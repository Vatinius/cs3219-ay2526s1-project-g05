set_real_ip_from 10.5.0.0/16;          # or: set_real_ip_from 172.18.0.0/16;
real_ip_header X-Forwarded-For;
real_ip_recursive on;                  # walk XFF to the last non-trusted IP

limit_req_zone $binary_remote_addr zone=peerpreplimit:20m rate=15r/s;

# These upstreams are used for load-balancing
upstream user_service {
    zone user_service 64k;
    server peerprep_user_service:4001;
    # When you spawn multiple instances of user_service using --scale in docker-compose,
    # Docker resolves this hostname to multiple IPs. (Multiple A Records)
    # When NGINX sees receives multiple IPs, it creates a "server" directive for each IP
    # By default, when there are multiple server directives, NGINX uses a round-robin load-balancer
}

upstream question_service {
    zone question_service 64k;
    server peerprep_question_service:4002;
}

upstream matching_service {
    zone matching_service 64k;
    server peerprep_matching_service:4003;
}

upstream collaboration_service {
    zone collaboration_service 64k;
    hash $arg_affinity consistent;

    server peerprep_collaboration_service:4004;
    server peerprep_collaboration_service_2:4004;
    # However, as issue here is that sessions affinity does not work well with the automatic "server" directive creation from multiple IPs
    # See issue here: https://github.com/nginx/nginx/issues/523
}

upstream code_execution_service {
    zone code_execution_service 64k;
    server peerprep_code_execution_service:4005;
}

log_format collab_debug '$remote_addr "$request" '
                        'aff=$arg_affinity upstream=$upstream_addr';

access_log /var/log/nginx/collab_debug.log collab_debug;


server {
        listen       80 default_server;       # Catch all IPv4 HTTP requests
        listen       [::]:80 default_server;  # Catch all IPv6 HTTP requests

        root /usr/share/nginx/html;
        
        location / {
            try_files $uri $uri.html $uri/ /index.html;
        }
        
        location ^~ /api/users/ {
            limit_req zone=peerpreplimit burst=10;

            include proxy_params;
            proxy_http_version 1.1;

            proxy_pass http://user_service;
            rewrite ^/api/users/(.*)$ /$1 break;
        }

        location ^~ /api/questions/ {
            limit_req zone=peerpreplimit burst=10;
            include proxy_params;
            proxy_http_version 1.1;

            proxy_pass http://question_service;
            rewrite ^/api/questions/(.*)$ /$1 break;
        }

        location ^~ /api/run/ {
            limit_req zone=peerpreplimit burst=10;
            include proxy_params;
            proxy_http_version 1.1;

            proxy_pass http://code_execution_service;
            rewrite ^/api/run/(.*)$ /$1 break;
        }

        location ^~ /api/collaboration/ {
            limit_req zone=peerpreplimit burst=10;
            include proxy_params;
            proxy_http_version 1.1;               # required for WebSocket
            # Websocket related settings
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_buffering off;                  # Avoids buffering WS frames - just in case
            proxy_read_timeout 3600s;
            proxy_send_timeout 3600s;

            proxy_pass http://collaboration_service;
            rewrite ^/api/collaboration/(.*)$ /$1 break;
        }

        location ^~ /api/matching/ {
            limit_req zone=peerpreplimit burst=10;
            include proxy_params;
            proxy_http_version 1.1;
            # SSE related settings
            proxy_buffering off;               # do not buffer the SSE msgs
            proxy_read_timeout 3600s;            

            proxy_pass http://matching_service;
            rewrite ^/api/matching/(.*)$ /$1 break;
        }
}